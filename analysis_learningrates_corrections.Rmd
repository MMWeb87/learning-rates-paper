---
title: "The effect of exchange rate fluctuations on learning rates and a method to correct for it"
subtitle: Sourcefile and calculations
editor_options:
  chunk_output_type: inline
output:
  html_document:
    df_print: paged
    toc_depth: '2'
  html_notebook: default
  pdf_document:
    highlight: zenburn
    keep_tex: yes
    number_sections: yes
    toc_depth: 2
params:
  capacity_data: IRENA
  capacity_threshold: 5
  base_currency: USD
  exchange_rate_norm_year: 2006
  deflate: yes
  default_digits: 2
  debug: no
  use_kable: no
  run_test: no
bibliography: bib.bib
---

```{r setup, include=FALSE}

library(knitr)
library(ggsci)
library(gridExtra)
library(tidyverse)
library(lubridate)
library(glue)
library(cowplot)
library(ggrepel)

source("functions_learning.R")
source("init.R")


base_currency <- params$base_currency
deflation_text <- if_else(params$deflate, "real costs", "nominal costs")
version <- if_else(params$deflate, "real", "nominal")


# for report
currencies_print <- paste(relevant_currencies, collapse=", ")

knitr::opts_chunk$set(
  echo = TRUE, 
  message = FALSE, 
  warning = FALSE,
  fig.width=fig.width.baseline*output.size, 
  out.width=out.width.default)

theme_set(theme_bw(base_size = 9.5) + theme(
  legend.title=element_blank(),
  legend.spacing.x = unit(0.1, 'cm')))

```


# Results for PV -- in base currency `r params$base_currency` & with `r params$capacity_data` marketshare in `r deflation_text` 

This file contains all of the calculations for @Lilliestam:kkhBHeo. 

## Parameters

We chose `r length(relevant_currencies)` relevant currencies (`r currencies_print`) and calculate a learning rate between `r T0` and `r T_max`. We look only at PV projects above `r params$capacity_threshold` MW.

# Data

## Translation tables
These tables convert strings into other strings, mostly used for currency and country code conversion.

```{r translation tables}

# long currency codes to short codes (We consistently use the short ISO currency codes)
long_to_short_currencycode_mappingtable <- read_csv(filenames$long_to_short_currencycode_translation) %>%
  select(local_currency_short = short, local_currency_long = long)

# country short codes to currencies
country_to_currencycode_mappingtable <- read_csv(filenames$country_to_currency_translation)
country_short_to_currency <- data.frame(currency = country_to_currencycode_mappingtable$currency)
rownames(country_short_to_currency) <- country_to_currencycode_mappingtable$country_short

# currency to currency area
currency_to_currency_area_translation <- read_csv(filenames$currency_to_currency_area_translation) %>% 
  select(currency = "currency", currency_area) %>% 
  mutate(currency_area = fct_relevel(currency_area, plot_order_country))

```


## Load and prepare BNEF data

Our analysis is based on the Bloomberg New Energy Finance (BNEF) renewable energy database. The dataset is copyright protected and can not be shared. We use the BNEF dataset because it gives investment costs for individual installations and projects in the original currencies, or allows for conversion to the domestic currency of each project.

As base unit, we use local value per capacity (e.g. USD/W)

```{r Read BNEF dataset}

data_projects <- read_csv(
    file = filenames$bnef_data, 
    col_types = cols(
      `Financing Date` = col_date(format="%Y-%m-%d")),
    na = c("","NA")) %>%
  select(
    id = `Renewable Project ID`,
    capacity = `Capacity - total (MWe)`,
    total_local_value = `Total Value (Local)`,
    total_usd_value = `Total Value ($m)`,
    local_currency_long = `Local Currency`,
    country = Country,
    date = `Financing Date`,
    status = Status) %>% 
  mutate(
    local_value = total_local_value / capacity, # from million currency and MW to currency/W
    year = year(date)
  ) %>% 
  add_column(subset_name = "All projects")


```

We subset the data according to different criteria:
 
```{r subset BNEF dataset, echo=TRUE}

commissioned_projects <- filter(data_projects, 
    status == "Commissioned") %>% 
  mutate(subset_name = "BNEF commissioned")

large_projects <- filter(commissioned_projects,
    capacity >= params$capacity_threshold) %>% 
  mutate(subset_name = "BNEF >= 5MW")

relevant_projects <- filter(large_projects,
    !is.na(date)) %>% 
  mutate(subset_name = "BNEF with date")

projects_with_costs_with_outliers <- relevant_projects %>% 
  left_join(
    long_to_short_currencycode_mappingtable, 
    by = "local_currency_long") %>% 
  select(id, date, capacity, local_currency = local_currency_short, local_value, year) %>% 
  filter(
    !is.na(local_value),
    !is.na(local_currency),
    local_currency != "Other"
  ) %>% 
  mutate(
    subset_name = "BNEF with costs with outliers",
    local_currency = as.factor(local_currency))


```


### Outlier treatment

```{r Outlier treatment, fig.cap="Overview of BNEF data and outliers.", fig.width=fig.width.baseline}

outliers_table <- read_csv(filenames$outliers, col_names = c("id", "desc"), skip = 1)

projects_with_costs_with_outliers <- projects_with_costs_with_outliers %>%  
  mutate(outlier = id %in% outliers_table$id)

n_outliers <- sum(projects_with_costs_with_outliers$outlier)

# projects_with_costs
projects_with_costs <- projects_with_costs_with_outliers %>% 
  filter(outlier == FALSE) %>% 
  select(-outlier) %>% 
  mutate(subset_name = "BNEF with costs")

overview_plots_after <- list()
overview_plots_after_boxplot <- list()

for (var in unique(projects_with_costs_with_outliers$local_currency)) {
  
  overview_plots_after[[var]] <- projects_with_costs_with_outliers %>% 
    filter(local_currency == var) %>% 
    ggplot(aes(date, local_value, shape = outlier, col = outlier)) +
      geom_point() +
      scale_shape_manual(values = c(16, 9)) +
      scale_color_manual(values = c("black", "red")) +
      labs(x = "Year", 
           y = paste("Costs in", var),
          subtitle = paste("Projects reported in", var)) +
      theme(legend.position = "none")
}

with(overview_plots_after, grid.arrange(CNY,EUR,INR,JPY,GBP,USD, ncol=3, widths=c(1, 1, 1)))
```

From *projects_with_costs_with_outliers*, we exclude `r n_outliers` projects highlighted in the plot. Compare the outliers.csv for details and justifications

### Apply interval

```{r}

# Let's work only with the smaller dataset in the relevant we use.
projects_with_costs_in_interval <- filter(projects_with_costs,
  between(year, T0, T_max)) %>% 
  mutate(subset_name = "BNEF with costs")

```


### Overview

```{r Statistical number of BNEF}

stats <- list()

# Different BNEF statistics
stats[["number"]][["all_projects"]] <- nrow(data_projects)
stats[["capacity"]][["all_projects"]] <- sum(data_projects$capacity, na.rm = T)

stats[["number"]][["commissioned_projects"]] <- nrow(commissioned_projects)
stats[["capacity"]][["commissioned_projects"]] <- sum(commissioned_projects$capacity, na.rm = T)

stats[["number"]][["large_projects"]] <- nrow(large_projects)
stats[["capacity"]][["large_projects"]] <- sum(large_projects$capacity)

stats[["number"]][["relevant_projects"]] <- nrow(relevant_projects)
stats[["capacity"]][["relevant_projects"]] <- sum(relevant_projects$capacity)

stats[["number"]][["relevant_projects_with_costs_with_outliers"]] <- nrow(projects_with_costs_with_outliers)
stats[["capacity"]][["relevant_projects_with_costs_with_outliers"]] <- sum(projects_with_costs_with_outliers$capacity)

stats[["number"]][["relevant_projects_with_costs"]] <- nrow(projects_with_costs)
stats[["capacity"]][["relevant_projects_with_costs"]] <- sum(projects_with_costs$capacity)

stats[["number"]][["relevant_projects_with_costs_in_interval"]] <- nrow(projects_with_costs_in_interval)
stats[["capacity"]][["relevant_projects_with_costs_in_interval"]] <- sum(projects_with_costs_in_interval$capacity)


# Shares
stats[["number_share"]] <- stats$number/stats[["number"]][["commissioned_projects"]]
stats[["capacity_share"]] <- stats$capacity/stats[["capacity"]][["commissioned_projects"]]


## Overview table
summary_table_rows <- 5
summary_table <- tibble(
  "Filter criterium" = character(summary_table_rows),
  "Projects" = numeric(summary_table_rows),
  "Share projects" = numeric(summary_table_rows),
  "Capacity" = numeric(summary_table_rows),
  "Share capacity" = numeric(summary_table_rows))

summary_table[1,] <- list("All BNEF projects", stats[["number"]][["all_projects"]], NA, stats[["capacity"]][["all_projects"]], NA)


summary_table[2,]  <- list("Commissioned projects", stats[["number"]][["commissioned_projects"]], 1, stats[["capacity"]][["commissioned_projects"]], 1)

summary_table[3,]  <- list("Capacity >= 5MW", 
                           stats[["number"]][["large_projects"]],
                           stats[["number_share"]][["large_projects"]],
                           stats[["capacity"]][["large_projects"]],
                           stats[["capacity_share"]][["large_projects"]])


summary_table[4,]  <- list("With financing date reported", 
                           stats[["number"]][["relevant_projects"]],
                           stats[["number_share"]][["relevant_projects"]],
                           stats[["capacity"]][["relevant_projects"]],
                           stats[["capacity_share"]][["relevant_projects"]])

summary_table[5,]  <- list("With financing costs reported", 
                           stats[["number"]][["relevant_projects_with_costs_with_outliers"]],
                           stats[["number_share"]][["relevant_projects_with_costs_with_outliers"]],
                           stats[["capacity"]][["relevant_projects_with_costs_with_outliers"]],
                           stats[["capacity_share"]][["relevant_projects_with_costs_with_outliers"]])

summary_table[6,]  <- list("Without outliers", 
                           stats[["number"]][["relevant_projects_with_costs"]],
                           stats[["number_share"]][["relevant_projects_with_costs"]],
                           stats[["capacity"]][["relevant_projects_with_costs"]],
                           stats[["capacity_share"]][["relevant_projects_with_costs"]])

summary_table[7,]  <- list(paste("Between", names(intervals[3])), 
                           stats[["number"]][["relevant_projects_with_costs_in_interval"]],
                           stats[["number_share"]][["relevant_projects_with_costs_in_interval"]],
                           stats[["capacity"]][["relevant_projects_with_costs_in_interval"]],
                           stats[["capacity_share"]][["relevant_projects_with_costs_in_interval"]])

# Remove all projects for report. In GW.
summary_table_print <- summary_table %>% 
  mutate(Capacity  = Capacity/1000) %>% 
  slice(-1)
  

print_number_table(summary_table_print, caption = "Summary of our subsets of the BNEF dataset. All lower rows include the filter criteria from the upper rows. Capacity in GW.", digits = 2)


```


## Load and prepare IRENA data

We use IRENA dataset to calculate market shares. To get a good estimate of the learning rate, the underyling cummulative capacity should reflect the actual global deplyoment. For the calculations of the learning rates we need currency information that the IRENA dataset does not include. Hence, we assume that projects in a country were financed in the main currencies. Compare Step 1 of Method 2 for the graph.

```{r Load and prepare IRENA data}

# The irena dataset need to have the same format and apply the same criteria as the BNEF dataset (especially capacity threshold)

irena_data <- read_csv(filenames$irena_data) %>% 
  filter(
    Product == "Solar photovoltaic" | Product == "Solar Photovoltaic", 
    Type == "ONG",
    `Capacity (MW)` >= params$capacity_threshold) %>% 
  select(
    capacity_cum = `Capacity (MW)`,
    country = ISO, 
    year = Year) %>%
  arrange(country, year) %>% # need to sort, as I calculate the difference between each year in a loop
  mutate(capacity = capacity_cum) %>% # the simplest way to set the start capacity in each year 
  add_column(local_currency = NA) %>% 
  add_column(subset_name = "IRENA")

irena_data$local_currency <- as.character(irena_data$local_currency)


# We loop through the dataset, because we can both set the irena_data$local_currency and calculate yearly capacity additions instead of the cummulative capacity we have so far.
for(i in 1:nrow(irena_data)){
  
  ith_irena_country <- as.character(irena_data[i,"country"])

  # If the country is in the "country_to_currency_translation" list, it is relevant (rest ROW)
  if(ith_irena_country %in% rownames(country_short_to_currency)){
    irena_data[i,"local_currency"] <- as.character(country_short_to_currency[ith_irena_country,"currency"])
  } else {
    irena_data[i,"local_currency"] <- "Other"
  }

  if (i > 1){

    if(irena_data[i-1,"country"] == irena_data[i,"country"]){
      irena_data[i,"capacity"] <- irena_data[i,"capacity_cum"] - irena_data[i-1,"capacity_cum"]
    }    
  }  
}

rm(i,ith_irena_country)

```


## Exchange rates

Exchange rates are from OFX and OECD, and the defaltors are based on OECD Consumer Price Index (CPI) data. We take the yearly average as basis for our calculations

```{r load exchange rates}

exchange_rates_USD_per_month <- read_csv(filenames[["exchange_rates"]], col_types = cols(
    date = col_date(format = "%d.%m.%y"))) %>% 
  drop_na() %>% 
  add_column(USD = 1) %>% 
  select(date, !!relevant_currencies)

exchange_rates_USD_yearly_average <- exchange_rates_USD_per_month %>% 
  gather(-date, key = "currency", value = "er") %>% 
  mutate(year = year(date)) %>% 
  group_by(year, currency) %>% 
  summarise(average_er = mean(er)) %>% ungroup() %>% 
  spread(key = currency, value = average_er)

exchange_rates_in_base_currency_per_year <- exchange_rates_USD_yearly_average  
exchange_rates_in_base_currency_per_month <- exchange_rates_USD_per_month  

if(base_currency != "USD"){

  for(other_currency in relevant_currencies){
  
  exchange_rates_in_base_currency_per_year[other_currency] <- convert_exchange_rate(exchange_rates_USD_yearly_average, base_currency, other_currency)
  exchange_rates_in_base_currency_per_month[other_currency] <- convert_exchange_rate(exchange_rates_USD_per_month, base_currency, other_currency)
    
  }
}

exchange_rates_per_year <- exchange_rates_in_base_currency_per_year %>% 
  gather(one_of(relevant_currencies), key = "currency", value = "rate") %>% 
  select(year, everything()) %>% 
  add_column(base_currency = base_currency)

exchange_rates_per_month <- exchange_rates_in_base_currency_per_month %>% 
  gather(one_of(relevant_currencies), key = "currency", value = "rate") %>%
  mutate(year = year(date), month = month(date)) %>% 
  select(year, month, date, everything()) %>% 
  add_column(base_currency = base_currency)


```


```{r exchange rate plot, echo=FALSE, fig.asp=0.6, fig.cap="Development of exchange rates of the main markets for large-scale PV 2006-2016, indexed USD-XXX January 2006=1 ", fig.width=fig.width.baseline * 0.8}

exchange_rates_norm <- exchange_rates_per_month %>% 
  filter(year == params$exchange_rate_norm_year, month == 1) %>% 
  rename(norm_rate = rate) %>% 
  select(currency, norm_rate)

exchange_rates_index <- exchange_rates_per_month %>% 
  left_join(exchange_rates_norm, by = c("currency")) %>% 
  mutate(normed_rate = rate / norm_rate) %>% 
  filter(between(year, T0, T_max))

exchange_rates_index$currency <- factor(exchange_rates_index$currency, plot_order_currency)

exchange_rates_plot <- ggplot(exchange_rates_index, aes(x = date, y = normed_rate, col = currency, linetype = currency)) +
  geom_line() +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  scale_linetype_manual(values = plot_order_linetype) +
  scale_color_manual(values = plot_colours_currencies) +
  labs(x = "", 
       y = paste("Index of", base_currency ,"exchange rate (Jan 2006)")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1,vjust = 0.5 ))

```



## Deflators


```{r calculate delfators}

## Deflators
# load yearly deflators
cpi_deflators <- read_csv(filenames$deflators) %>% 
  select(country = LOCATION, year = TIME, value = Value)


prepare_cpi_data <- function(cpi_data, ref_year = 2017){
  
  # prepare to change the values to the reference year (2017)
  cpi_deflators_index_year <- cpi_data %>% 
    filter(year == !!ref_year, country %in% relevant_deflators) %>% 
    select(country, value_index = value)
  
  cpi_data %>% 
    left_join(cpi_deflators_index_year) %>% 
    mutate(
      currency = country_short_to_currency[country,"currency"],
      defl = value / value_index) %>% 
    select(year, currency, defl) %>% 
    filter(defl, !is.na(currency))  
  
}


defl <- prepare_cpi_data(cpi_deflators)

cpi_inflator <- defl %>% 
  left_join(
    defl %>% 
      mutate(year = year + 1) %>% 
      rename(defl_prev = defl)
    ) %>% 
  filter(!is.na(defl_prev)) %>% 
  mutate(rate = defl / defl_prev)


```


```{r Deflator plot, echo=FALSE, fig.asp=0.6, fig.cap="Deflation", fig.width=fig.width.baseline * 0.8}

defl_plot <- subset(defl, year>=1980, year<=T_max)
defl_plot$year <- ymd(paste(defl_plot$year,"-01-01"))

delfator_plot <- defl_plot %>% 
  left_join(currency_to_currency_area_translation) %>% 
  ggplot(aes(year, defl, col = currency_area, linetype = currency_area)) + 
    geom_line() + 
    scale_linetype_manual(values=plot_order_linetype) +
    scale_colour_manual(values = plot_colours_country) +
  
    labs(
      x = "Year",
      y = "Deflators relative to 2017"
    )


inflator_plot <- cpi_inflator %>% 
  mutate(year = ymd(paste(year,"-01-01"))) %>% 
  left_join(currency_to_currency_area_translation) %>% 
  ggplot(aes(year, rate, col = currency_area, linetype = currency_area)) + 
    geom_line() + 
    scale_linetype_manual(values=plot_order_linetype) +
    scale_colour_manual(values = plot_colours_country) +
  
    labs(
      x = "Year",
      y = "Inflation rates"
      #subtitle = "Deflators are based on CPIs"
      )

delfator_plot
```

```{r, fig.asp=0.6, fig.cap="Deflation", fig.width=fig.width.baseline * 0.8}
inflator_plot
```

## Cumulative sums

X is the global cumulative deployment in year t -> cummulative sum of x_global (sum of xj) per year

```{r Calculate cumulative sums, fig.cap="Cumulative sums of different datasubsets", fig.asp=0.9, fig.width=fig.width.baseline * 0.65}

x_global <- list(
  "BNEF" = projects_with_costs_in_interval, 
  "IRENA" = irena_data) %>% 
  map(calculate_cummulative_sums)

X_all_subsets <- x_global %>% 
  reduce(bind_rows) %>% 
  group_by(subset_name) %>% 
  mutate(X = cumsum(x_global))

X <- X_all_subsets %>% 
  filter(subset_name == params$capacity_data) %>% 
  select(year, X)

```

# Learning rate calculations

We calculate 3 types of learning rates in this file:

- uncorrected project-weighted learning rates
- uncorrected marketshare-weighted learning rates
- corrected marketshare-weighted learing rates

For a detailed explanation of the theories behind the learning rates calculations and currency corrections, see our paper.

## Method 1: Calculation of the uncorrected project-weighted learning rates 

We don't describe this approach in our paper. Compare Method 2. The results for the uncorrected project-weighted are the same, though.

To calculate the uncorrected project-weighted learning rates, we convert **all available project costs** to different currencies. We then derive the learning rate for each currency from the global average costs $C_{global,t,2017}^{i}$ of all available projects.

```{r}
results_new <- list()
```

### Step 1: Calculation of costs in every relevant currency
In the first step, we calculate the value for each project in each relevant currency (`r currencies_print`).

```{r Calculate uncorrected_project_weighted learning rates}

projects_with_costs_in_currencies <- projects_with_costs_in_interval

# add columns for each currency
projects_with_costs_in_currencies[relevant_currencies] <- NA

for(j in 1:nrow(projects_with_costs_in_currencies)){
  
  project_year_j = projects_with_costs_in_currencies[[j,"year"]]
  local_currency_j = as.character(projects_with_costs_in_currencies[[j,"local_currency"]])

  projects_with_costs_in_currencies[[j, base_currency]] <- #
    projects_with_costs_in_currencies[[j,"local_value"]] * get_exchange_rate_for_project(exchange_rates_per_year, project_year_j, local_currency_j)
  
  
  for(relevant_currency in relevant_currencies){
    if(relevant_currency!=base_currency){
      projects_with_costs_in_currencies[[j, relevant_currency]] <- #
        projects_with_costs_in_currencies[[j, base_currency]] / get_exchange_rate_for_project(exchange_rates_per_year, project_year_j, relevant_currency)
    }
  }
}

rm(j, project_year_j, local_currency_j)


```

### Step 2. Aggregate data to means

In the second step, we aggregate the data by yearly averages for each currency. 



```{r aggregate to average costs, echo=TRUE}

average_global_costs_uncor <- projects_with_costs_in_currencies %>% 
  select(year, !!relevant_currencies) %>% 
  gather("currency", "value", !!relevant_currencies) %>% 
  group_by(currency, year) %>% 
  summarise(nominal_costs = mean(value)) %>% 
  ungroup()

```

### Step 3. Deflate to real values (2017)

Here we deflate the average to 2017 real values if params\$deflate is set true. Currently: `r params$deflate`.

```{r}
average_global_costs_uncor <- convert_to_real_costs(average_global_costs_uncor, defl)
```

### Step 4. Calculation of learning rates

We do a regression over global average costs P and cummulative capacity X to calculate the learning rate in each interval and for each currency.

```{r Calculation of learning rates method 1}

results_list <- list()

for(j in seq_along(relevant_currencies)){
  currency <- relevant_currencies[[j]]

  for(i in seq_along(intervals)){
    interval <- intervals[[i]]
    interval_name <- names(intervals[i])
    interval_years <- as.numeric(interval[1]):as.numeric(interval[2])
    
    regression_costs <- average_global_costs_uncor %>% 
      filter(year %in% !!interval_years, currency == !!currency) %>% 
      pull(average_costs)
    
    regression_cumulative_capacity <- X %>% 
      filter(year %in% interval_years) %>% 
      pull(X)
    
    l <- calculate_learning_rate(regression_costs, regression_cumulative_capacity)
    
    results_list[[paste0(currency,interval_name)]] <- to_results_list(l, currency, interval_name)
    
  }
}

results_new[["uncorrected_project_weighted"]] <- results_list %>% 
  reduce(bind_rows) %>% 
  add_column(type = factor("uncorrected_project_weighted")) %>% 
  arrange_by_currencies(table_order_currency)

rm(currency, results_list)
  
```

### Results

```{r Learning rate table, fig.cap="Simple learning rates in different intervals.", fig.width=fig.width.baseline * 0.7, fig.asp= 0.7}

print_learning_rates_result(results_new[["uncorrected_project_weighted"]])

```

### Combined plot

To plot all learning rates in the same plot, it is necessary to norm the costs. To do this, we select the initial year's average global costs and divide all average global costs by that value. We then get 1/W for all average costs and can compare the learning rates.

```{r Combined and normed plot, echo=FALSE, fig.cap="Comparison of learning rates, as index of the average costs in 2006", fig.width=fig.width.baseline*output.size, fig.asp=0.4, out.width=out.width.default}

combined_plot_data <- average_global_costs_uncor %>% 
  inner_join(X) %>% 
  filter(year >= T0, year <= T_max) %>% 
  select(
    year, 
    average_costs, 
    currency, 
    cumulative_capacity = X) %>% 
  mutate(currency = factor(currency, plot_order_currency))

combined_plot_norm_data <- combined_plot_data %>% 
  filter(year == T0) %>% 
  select(norm_costs = average_costs, currency)
  
normed_plot_data <- combined_plot_data %>% 
  inner_join(combined_plot_norm_data, by = "currency") %>% 
  mutate(normed_average_costs = average_costs / norm_costs) %>% 
  arrange(currency, year)

normed_plot_data_subsets <- list()
for(i in seq_along(intervals)){
  interval <- intervals[[i]]
  interval_name <- names(intervals[i])
  interval_years <- as.numeric(interval[1]):as.numeric(interval[2])
  
  x_for_abclabel <- normed_plot_data %>% 
    filter(year %in% interval_years[[1]]) %>% 
    pull(cumulative_capacity)
  x_for_abclabel <- x_for_abclabel[[1]]/1000
  
  normed_plot_data_subsets[[i]] <- normed_plot_data %>% 
    filter(year %in% interval_years) %>% 
    add_column(interval = interval_name) %>% 
    add_column(x_for_abclabel = !!x_for_abclabel)
}

normed_plot_data_reduced <- normed_plot_data_subsets %>% 
  reduce(bind_rows) %>% 
  mutate(
    interval = fct_relevel(interval, names(intervals)),
    interval = fct_recode(interval,!!!plot_stips_label))

plot_labels <- normed_plot_data_reduced %>% 
  expand(interval) %>% 
  add_column(label = letters[seq( from = 1, to = 3 )])

normed_plot_data_reduced %>% 
  mutate(year_for_text = if_else(currency == "GBP", str_sub(as.character(year), start = 3, end = 4) , "")) %>%
  ggplot(aes(cumulative_capacity/1000, normed_average_costs)) +
    geom_smooth(
      aes(col = currency),
      method="lm", formula = (y ~ x), se=FALSE) +
    geom_point(aes(col = currency)) +
    geom_text_repel(aes(label = year_for_text), vjust = -0.6, hjust = 0.1, size = 3, point.padding = NA) +
    geom_text(data = plot_labels, mapping = aes(x = c(250,60,250), y = c(1.2,1.2,1.2), label = label), fontface = "bold") +

    scale_x_continuous(trans="log", breaks = c(c(1,seq(2,10,2)) %o% 10^(0:4)), minor_breaks = 0.5) +
    scale_y_continuous(trans="log", breaks = c(seq(0,1,0.1), seq(1.2,2,0.2)), minor_breaks = NULL) +
    theme(legend.position="bottom") +
    guides(
      linetype = guide_legend(title="Learning rate", nrow = 1), 
      col = guide_legend(title="Learning rate", nrow = 1), 
      size = guide_legend(title="Type")) +
    labs(x = "Cumulative capacity [GW]", 
         y = paste0("Index of costs per MW")) +
    scale_color_manual(values = plot_colours_currencies) +
  facet_grid( ~ interval, scales = "free_x", space = "free_x")


```
\clearpage


As asked by reviewer:

```{r, fig.asp=0.4, out.width=out.width.default}

normed_plot_data_reduced %>% 
  mutate(year_for_text = if_else(currency == "GBP", str_sub(as.character(year), start = 3, end = 4) , "")) %>%
  ggplot(aes(cumulative_capacity/1000, normed_average_costs)) +
    geom_smooth(
      aes(col = currency, linetype = interval),
      method="lm", formula = (y ~ x), se=FALSE) +
    #geom_point(aes(col = currency)) +
    #geom_text_repel(aes(label = year_for_text), vjust = -0.6, hjust = 0.1, size = 3, point.padding = NA) +
    #geom_text(data = plot_labels, mapping = aes(x = c(250,60,250), y = c(1.2,1.2,1.2), label = label), fontface = "bold") +

    scale_x_continuous(trans="log", breaks = c(c(1,seq(2,10,2)) %o% 10^(0:4)), minor_breaks = 0.5) +
    scale_y_continuous(trans="log", breaks = c(seq(0,1,0.1), seq(1.2,2,0.2)), minor_breaks = NULL) +
    theme(legend.position="right") +
    # guides(
    #   linetype = guide_legend(title="Learning rate", nrow = 1), 
    #   col = guide_legend(title="Learning rate", nrow = 1), 
    #   size = guide_legend(title="Type")) +
    labs(x = "Cumulative capacity [GW]", 
         y = paste0("Index of costs per MW"),
         linetype = "Interval",
         col = "Currency") +
    scale_color_manual(values = plot_colours_currencies) #+
  #facet_grid( ~ , scales = "free_x", space = "free_x")


```



## Method 2: Calculation of all three types of learning rates 

In this part we calculate all three types of learning rates in the base currency **`r base_currency`**. The project-weighted uncorrected learning rate is the same as above, but calculated using an approach that is in line with our paper.

### Step 1: Marketshare calculation

A notable difference to the uncorrected project-weighted learning rate, is that we weighting the average global costs by the marketshares $\delta$. For those, we have two datasources. (1) BNEF which is also used to calculate the learning rates and (2) IRENA. In our paper, we use the IRENA data.

```{r Calculation of market shares}

# calculation of market share weights for the markes share-weighted learning rates

delta_BNEF <- calculate_delta(projects_with_costs_in_interval, x_global$BNEF)
delta_IRENA <- calculate_delta(irena_data, x_global$IRENA)

if(params$capacity_data == "IRENA"){
  delta <- delta_IRENA
} else {
  delta <- delta_BNEF
}

# calculation of project count weights for the project-weighted learning rates

delta_project_weighted <- left_join(
  projects_with_costs_in_interval %>% 
    group_by(year, local_currency) %>% 
    summarise(n = n()),
  
  projects_with_costs_in_interval %>% 
    group_by(year) %>% 
    summarise(n_tot = n())
) %>% 
  mutate(delta = n/n_tot) %>% 
  rename(currency = local_currency) %>% 
  complete(year, currency) %>% 
  replace_na(replace = list(n = 0, n_tot = 0, delta = 0))

```


#### Marketshare plots (`r params$capacity_data`)

The market share of PV deplyoment in each currency and year is relevant. To calculate the market share of different currencies, we derive delta values from BNEF and IRENA datasets. Figure 1 visualises the market shares as a function of the currency.

```{r Marketshare plots comparison, fig.cap = "Comparison of capacity additions per year and currency area in BNEF and IRENA dataset", fig.width=fig.width.baseline, fig.asp=0.45, out.width=out.width.default}

bind_rows(delta_BNEF,delta_IRENA) %>% 
  get_delta_plot(plot_type = "absolute") +
  facet_grid(cols = vars(subset_name))

bind_rows(delta_BNEF,delta_IRENA) %>% 
  get_delta_plot(plot_type = "relative", legend = TRUE) +
  facet_grid(cols = vars(subset_name))


```

```{r Marketshare plots current, fig.cap = "Capacity additions per year and currency area", fig.width=fig.width.baseline*output.size, fig.asp=0.8, out.width=out.width.default}

plot_marketshare_absolute <- get_delta_plot(delta, plot_type = "absolute")
plot_marketshare_legend <- get_legend(plot_marketshare_absolute)
plot_marketshare_absolute <- plot_marketshare_absolute + theme(legend.position = "none")

plot_marketshare_relative <-  get_delta_plot(delta, plot_type = "relative") + theme(legend.position = "none")

plot_marketshare_top_row <- plot_grid(
  plot_marketshare_absolute,
  plot_marketshare_relative,
  plot_marketshare_legend,
  labels = c("a", "b", ""), 
  rel_widths = c(1,1,0.4), align = "h", ncol = 3)


exchange_rates_plot_legend <- get_legend(exchange_rates_plot)
exchange_rates_plot_nolegend <- exchange_rates_plot + theme(legend.position = "none")

exchange_rates_plot_aligned <- align_plots(plot_marketshare_absolute, exchange_rates_plot_nolegend, align = 'v', axis = 'l')[[2]] 


plot_marketshare_bottom_row <- plot_grid(exchange_rates_plot_aligned, exchange_rates_plot_legend, labels = c('c', ''), rel_widths = c(2,0.4), align = "h", ncol = 2)

plot_grid(plot_marketshare_top_row, plot_marketshare_bottom_row, labels = c('', 'c'), ncol = 1, rel_heights = c(1, 1.2))


```




### Step 2: Aggregate data to means

C are observed average cost in currency i

```{r Calculation of average_local_costs or C}

## average_local_costs = C: observed average cost per MW in currency i in year t (i.e. not a subset of all projects) 

average_local_costs <- projects_with_costs_in_interval %>% 
  group_by(year, local_currency) %>% 
  summarise(C = mean(local_value)) %>% ungroup() %>%
  rename(currency = local_currency) %>% 
  complete(year, currency, fill = list(C = 0))

```

The table shows which currency have average_local_costs in which year. 

### Step 3: Calculation to the average global costs (P)

In the third step, we sum up local average costs to global average costs. We weight in the sum either by number of projects or market shares. We calculate three different $P$.

```{r Calculation of the weighted average global cost P}

## w: exchange rate between currency i and the base currency l in price notation
# e.g. "5 lead-dollars / 1 Euro" 

# I changed to variable names that are used in the paper
C <- average_local_costs

numeric_P_comp <- numeric(length(all_years) * length(relevant_currencies))

alpha <- tibble(
  "currency" = rep(relevant_currencies, length(all_years)),
  "year" = rep(all_years, length(relevant_currencies)),
  "alpha" = numeric_P_comp
)

P_comp <- tibble(
  "base_currency" = base_currency,
  "currency" = rep(relevant_currencies, length(all_years)),
  "year" = rep(all_years, length(relevant_currencies)),
  "nominal_costs" = numeric_P_comp
) %>% inner_join(defl, by = c("currency", "year"))

P_comp_tilde <- P_comp
P_comp_pwt <- P_comp

for(t in all_years){
  
  for(i in relevant_currencies){

    w_i_t <- filter(exchange_rates_per_year, year == t, currency == i) %>% pull(rate)
    w_i_0 <- filter(exchange_rates_per_year, year == T0, currency == i) %>% pull(rate)
    C_i_t <- filter(C, year == t, currency == i) %>% pull(C)
    
    mu_i_t <- filter(delta_project_weighted, year == t, currency == i) %>% pull(delta)
    P_comp_pwt[P_comp_pwt$year == t & P_comp_pwt$currency == i, "nominal_costs"] <- mu_i_t * w_i_t * C_i_t

    delta_i_t <- filter(delta, year == t, currency == i) %>% pull(delta)
    P_comp[P_comp$year == t & P_comp$currency == i, "nominal_costs"] <- delta_i_t * w_i_t * C_i_t
    P_comp_tilde[P_comp$year == t & P_comp$currency == i, "nominal_costs"] <- delta_i_t * w_i_0 * C_i_t
    
  }
  
}

P <- list()

P[["uncorrected_project_weighted2"]] <- calculate_P(P_comp_pwt) #p -> we actually do the same calculation in Method 1, but do it here again to check if both give the same result. In the paper we describe the approach in this section.

P[["uncorrected_marketshare_weighted"]] <- calculate_P(P_comp) # P 
P[["corrected_marketshare_weighted"]] <- calculate_P(P_comp_tilde) # P_tilde  

```

### Step 4. Deflate to real values

We defalte after the currency conversion. I.e. the learning rates of multiple base currencies will only be the same for nominal costs. For real costs, the deflator of different base currencies lead to different learning rates.

Only if params\$deflate is true. Currently: `r params$deflate`

```{r}

P <- map(P, convert_to_real_costs, defl)

```


### Step 5: Calculation of the learning rate

We do a regression over global average costs P and cummulative capacity X to calculate the learning rates the base currency.

```{r Calculation of learning rates method 2}

types <- c(
  "uncorrected_project_weighted2",
  "uncorrected_marketshare_weighted",
  "corrected_marketshare_weighted")

results_list <- list(
  "uncorrected_project_weighted2" <- list(),
  "uncorrected_marketshare_weighted" <- list(),
  "corrected_marketshare_weighted" <- list()
)

for(type in types){
  
  for(i in 1:length(intervals)){
    interval <- intervals[[i]]
   
    interval_years <- as.numeric(interval[1]):as.numeric(interval[2])
    interval_name <- names(intervals[i])
    
    regression_costs <- P[[type]] %>% 
      filter(year %in% interval_years) %>% 
      pull(average_costs)
    
    regression_cumulative_capacity <- X %>% 
      filter(year %in% interval_years) %>% 
      pull(X)
    
    l <- calculate_learning_rate(regression_costs, regression_cumulative_capacity)
    
    results_list[[type]][[interval_name]] <- to_results_list(l, base_currency, interval_name)

  }
  
  results_new[[type]] <- results_list[[type]] %>% 
      reduce(bind_rows) %>% 
      add_column(type = factor(type)) 
}

rm(results_list)
```

## Method 2: Results

We get the following learning rates using the corrected_marketshare_weighted learning rates approach:

```{r Results table}

print_learning_rates_result(results_new[["uncorrected_project_weighted"]])
print_learning_rates_result(results_new[["uncorrected_project_weighted2"]])

print_learning_rates_result(results_new[["uncorrected_marketshare_weighted"]])
print_learning_rates_result(results_new[["corrected_marketshare_weighted"]])

```

## Combined plot of simple and corrected_marketshare_weighted learning rates

Comparison with the simple learning rates for every country

```{r Combined plot, fig.cap="Learning rates plot", fig.asp=0.4}

#mypal = pal_npg("nrc")(length(relevant_currencies))

corrected_rates <- results_new$corrected_marketshare_weighted %>% 
  select(corrected_lr = estimate, interval)

combined_plot_data <-
  bind_rows(
    results_new$corrected_marketshare_weighted %>% 
      add_column(legend = factor("fx-corrected (USD)")),
    results_new$uncorrected_project_weighted %>% 
      mutate(legend = currency)
    ) %>% 
  rename(lr = estimate) %>%  
  left_join(corrected_rates, by = c("interval")) %>% 
  mutate(
    lr = round(replace_na(lr, replace = 0),digits = 1),
    diff = round(lr - corrected_lr, digits = 1),
    diff_text = paste0(if_else(diff > 0, "+", ""), diff)) %>% 
  mutate(
    interval = fct_relevel(interval, names(intervals)),
    interval = fct_recode(interval,!!!plot_stips_label))
  
plot_factors <- c("fx-corrected (USD)","",table_order_currency)

plot_labels <- combined_plot_data %>% 
  expand(interval) %>% 
  add_column(label = letters[seq( from = 1, to = 3 )])

plot <- combined_plot_data %>% 
  mutate(legend = factor(legend, plot_factors),
         legend = fct_relevel(legend, plot_factors)) %>% 

  ggplot(aes(fill = legend, y = lr, x = legend)) + 
    geom_bar(position="dodge", stat="identity") +
    geom_hline(aes(yintercept = corrected_lr)) + 
    geom_segment(. %>% filter(legend %in% relevant_currencies), 
                 mapping=aes(x = legend, xend = legend, y = corrected_lr, yend=lr), 
                 arrow = arrow(length = unit(0.05, "inches"), type = "closed"), 
                 size = 1, color="black") +
    geom_text(. %>% filter(legend != ""), mapping = aes(y = lr/2, label = lr), col = "white", size = 3) + # learning rates
    geom_label_repel(. %>% filter(legend %in% relevant_currencies), mapping = aes(label = diff_text), nudge_y = 2, fill = "white", size = 3) + # differences
    
    geom_text(data = plot_labels, mapping = aes(x = 1, y = 40, label = label, fill = "USD"), fontface = "bold") +

    scale_fill_manual(values = c("fx-corrected (USD)" = "#000000", plot_colours_currencies)) +
    scale_y_continuous(limits = c(0,40), expand = expand_scale(mult = c(0, 0.1))) +
    scale_x_discrete(drop = FALSE) +
    labs(
      y = paste0("Learning rate in %")) +
    theme(
      axis.title.x = element_blank(),
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank(), 
      panel.grid.major = element_blank(),
      legend.position="bottom") +
    guides(
      fill = guide_legend(nrow=1,byrow=TRUE)) +
  facet_grid( ~ interval)


plot

```

```{r Save results to csv}


results_new %>% 
  reduce(bind_rows) %>% 
  filter(type!="uncorrected_project_weighted2") %>% 
  add_column(version = version) %>% 
  write_csv(paste0("output/results/learning_rate_results_",params$base_currency,"_",version,".csv"))

```

# Bibliography
